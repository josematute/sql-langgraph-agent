# copy example.env to .env

# Model Provider Configuration
# Options: "openai" (default) or "bedrock"
# If not set, defaults to OpenAI. If AWS credentials are present, will auto-detect Bedrock.
# MODEL_PROVIDER=openai
# MODEL_PROVIDER=bedrock

# OpenAI Configuration (default)
OPENAI_API_KEY=your_openai_api_key_here

# AWS Bedrock Configuration (optional)
# Use either AWS credentials OR AWS profile, not both
# AWS_ACCESS_KEY_ID=your_aws_access_key_id
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
# AWS_SESSION_TOKEN=your_aws_session_token  # Optional, for temporary credentials
# AWS_REGION=us-east-1  # Optional, defaults to us-east-1
# AWS_PROFILE=your_aws_profile_name  # Optional, alternative to credentials
# BEDROCK_MODEL_ID=anthropic.claude-haiku-4-5-20251001-v1:0  # Optional, defaults to Claude Haiku

# Optional: For evaluation and tracing
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_TRACING=true
LANGSMITH_PROJECT=pg-langgraph-agent

# Optional: Database connection
# If not set, defaults to local Docker database (postgresql://postgres:postgres@localhost:5432/sample_db)
# To use your own database, uncomment and set:
# POSTGRES_URI=postgresql://user:password@host:port/database
